{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIYovqBGryVz"
      },
      "source": [
        "# MSCI 436 Team 8 ML Decision Model\n",
        "1. Import packages\n",
        "2. Load Data\n",
        "3. Clean Data\n",
        "4. Fit a LR model\n",
        "5. Model Evaluation\n",
        "6. Streamlit\n",
        "7. References for code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDpgfrCBFYDx"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywE63x8pFTab"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Model - All feature variables selected"
      ],
      "metadata": {
        "id": "s1vV1Ai0AbRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Data**"
      ],
      "metadata": {
        "id": "2az9mTDKAV_T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uydYBrtjFcyh"
      },
      "outputs": [],
      "source": [
        "# Loading in required data\n",
        "raw_data_train = pd.read_csv('https://raw.githubusercontent.com/jmpark0808/pl_mnist_example/main/train_hp_msci436.csv')\n",
        "raw_data_train.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoW_4p2Y2_no"
      },
      "outputs": [],
      "source": [
        "raw_data_train.tail()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View shape of data\n",
        "print(raw_data_train.shape)"
      ],
      "metadata": {
        "id": "e1IG1LMxECqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cleaning Data**"
      ],
      "metadata": {
        "id": "yRH-uKuDAQdR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cRX-l7prKwc"
      },
      "outputs": [],
      "source": [
        "df = raw_data_train\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mrWJ60Fmrgs"
      },
      "outputs": [],
      "source": [
        "# View SalePrice metrics\n",
        "df['SalePrice'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POmpz3DHmb95"
      },
      "outputs": [],
      "source": [
        "# Plotting SalePrice\n",
        "sns.displot(df['SalePrice']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EJKlfTNoNiu"
      },
      "outputs": [],
      "source": [
        "# Scatterplot for given features\n",
        "sns.set()\n",
        "cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'TotalBsmtSF', 'YearBuilt']\n",
        "sns.pairplot(df[cols], height = 2)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking Null Values**"
      ],
      "metadata": {
        "id": "WSY1p8wCAhj-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUIB6iRS2DV3"
      },
      "outputs": [],
      "source": [
        "# checking for null values\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goBAI-aN5Rc9"
      },
      "outputs": [],
      "source": [
        "print(df[df['LotFrontage'].isnull() | (df['LotFrontage'] == 0)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97Id7AR1u5wS"
      },
      "source": [
        "In this case 0 could just mean that there is no street connected to the property, 0 is fine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etSovZkMtt71"
      },
      "outputs": [],
      "source": [
        "# Citation at end of notebook\n",
        "# Checking which features are the more irrelevant (most houses don't have this feature)\n",
        "# Count NaN and numeric 0 values\n",
        "total = df.isna().sum().sort_values(ascending=False)\n",
        "\n",
        "# Calculate percentage of NaN and numeric 0 values\n",
        "percent = (df.isna().sum() / len(df)).sort_values(ascending=False)\n",
        "\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "missing_data.head(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIE2vZu8y-d8"
      },
      "outputs": [],
      "source": [
        "# Dropping features with missing data\n",
        "df = df.drop((missing_data[missing_data['Total'] > 1]).index,1)\n",
        "df = df.drop(df.loc[df['Electrical'].isnull()].index)\n",
        "df.isnull().sum().max() #just checking that there's no missing data missing..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_TU2-jE07xp"
      },
      "outputs": [],
      "source": [
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking Categorical Variables**"
      ],
      "metadata": {
        "id": "aKaWwiEHAmGa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_UH733VBywc"
      },
      "outputs": [],
      "source": [
        "# Get column names with 'object' data type\n",
        "object_columns = df.select_dtypes(include='object').columns\n",
        "\n",
        "# Iterate over the 'object' columns\n",
        "for column in object_columns:\n",
        "    unique_values = df[column].unique()\n",
        "    print(f\"Column: {column}\")\n",
        "    print(unique_values)\n",
        "    print(\"--------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnSnK3MxDM7e"
      },
      "source": [
        "In this case, 0 just means that the house doesn't have that particular feature. It's not necessarily a missing value. This is important information. For example, a user might want to know if a pool vs no pool would make a significant difference in value in case they have a budget and space to add a pool."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One-hot encoding**"
      ],
      "metadata": {
        "id": "wDX1jYmtAqDn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TAZb9pR8cPW"
      },
      "outputs": [],
      "source": [
        "# Code for reference\n",
        "# Select the categorical columns to be one-hot encoded (excluding the '0' values)\n",
        "categorical_columns = df.select_dtypes(include='object').columns\n",
        "\n",
        "# Create a new DataFrame with the original '0' values intact\n",
        "encoded_df = pd.get_dummies(df, columns=categorical_columns, drop_first=False)\n",
        "\n",
        "# Print the encoded DataFrame\n",
        "print(encoded_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XydarK_P2soR"
      },
      "outputs": [],
      "source": [
        "df = encoded_df\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**"
      ],
      "metadata": {
        "id": "aiI0HUH7AvtV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "el3Uzq1Oa3ZZ"
      },
      "outputs": [],
      "source": [
        "# Filter for float64 and int64\n",
        "df_clean = df.select_dtypes(include = ['float64', 'int64']).fillna(0)\n",
        "X = df.loc[:, ~df.columns.isin(['SalePrice', 'Id'])]\n",
        "y = df[\"SalePrice\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Test Split**"
      ],
      "metadata": {
        "id": "c6hgPu-BAx7c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOyUQ5Bb2sjS"
      },
      "outputs": [],
      "source": [
        "# Initializing the testing and training split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.70, random_state=1)\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fit a Linear Regression Model**"
      ],
      "metadata": {
        "id": "mSCDttThA0IM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cK8G7vZJ4ac"
      },
      "outputs": [],
      "source": [
        "# Fitting the regression model and displaying the coefficient weights\n",
        "reg = LinearRegression().fit(X_train, Y_train)\n",
        "reg.coef_"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Evaluation**"
      ],
      "metadata": {
        "id": "e44ONnxMA7Ky"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5bfi7_9UA7V"
      },
      "outputs": [],
      "source": [
        "# MSE and MAE calculation\n",
        "reg_pred = reg.predict(X_test)\n",
        "reg_mse = mean_squared_error(Y_test, reg_pred)\n",
        "reg_mae = mean_absolute_error(Y_test, reg_pred)\n",
        "\n",
        "print(\"Mean Squared Error (MSE): \", reg_mse)\n",
        "print(\"Mean Absolute Error (MAE): \", reg_mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP749cVod7-N"
      },
      "source": [
        "# Revised Model With Selected Columns - Interface\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBWCW-FceBSC"
      },
      "outputs": [],
      "source": [
        "df_interface = raw_data_train\n",
        "df_interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PKa9RY6ffnc"
      },
      "outputs": [],
      "source": [
        "# Heatmap\n",
        "# Correlation matrix - checking which columns strongly correlate with the sale price\n",
        "corrmat = df_interface.corr()\n",
        "f, ax = plt.subplots(figsize=(12, 9))\n",
        "sns.heatmap(corrmat, vmax=.8, square=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXtcKwq7kGM7"
      },
      "outputs": [],
      "source": [
        "# Selecting the highly correlated columns and making a new df\n",
        "df_interface_v2 = df_interface[['OverallQual', 'LotFrontage','YearBuilt', 'YearRemodAdd',\n",
        "                             'MasVnrArea', 'TotalBsmtSF', 'BsmtFinSF1', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'FullBath',\n",
        "                             'HalfBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'SalePrice']].copy()\n",
        "df_interface_v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gt4osRXjlOvk"
      },
      "outputs": [],
      "source": [
        "# Checking which features are the more irrelevant (most houses don't have this feature)\n",
        "# Count NaN and numeric 0 values\n",
        "total = df_interface_v2.isna().sum().sort_values(ascending=False)\n",
        "\n",
        "# Calculate percentage of NaN and numeric 0 values\n",
        "percent = (df_interface_v2.isna().sum() / len(df)).sort_values(ascending=False)\n",
        "\n",
        "# Group and print missing data\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "missing_data.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJiKAfrnliVQ"
      },
      "outputs": [],
      "source": [
        "df_interface_v2 = df_interface_v2.drop((missing_data[missing_data['Total'] > 1]).index,1)\n",
        "\n",
        "# Checking that there's no missing data missing...\n",
        "df_interface_v2.isnull().sum().max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUdbz-Ej9oGK"
      },
      "source": [
        "**Hot encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdIVdrewlzW1"
      },
      "outputs": [],
      "source": [
        "# Select the categorical columns to be one-hot encoded (excluding the '0' values)\n",
        "categorical_columns = df_interface_v2.select_dtypes(include='object').columns\n",
        "\n",
        "# Create a new DataFrame with the original '0' values intact\n",
        "encoded_df = pd.get_dummies(df_interface_v2, columns=categorical_columns, drop_first=False)\n",
        "\n",
        "# Print the encoded DataFrame\n",
        "print(encoded_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1LTsrv69v3c"
      },
      "source": [
        "**Train & Test Data Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqm8alBUmA3w"
      },
      "outputs": [],
      "source": [
        "# when doing experiment you want to have a controlled chaos, random_state = 1, 1 is a non-negative integer seed\n",
        "# a seed will generate the same set of random numbers every time\n",
        "df_clean = encoded_df.select_dtypes(include = ['float64', 'int64']).fillna(0)\n",
        "X = encoded_df.loc[:, ~encoded_df.columns.isin(['SalePrice', 'Id'])]\n",
        "y = encoded_df[\"SalePrice\"]\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UTTgeZnKv9r"
      },
      "outputs": [],
      "source": [
        "X_test.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYTxnbGV9_V5"
      },
      "source": [
        "**Linear Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3A3b0OuvmWzi"
      },
      "outputs": [],
      "source": [
        "# Fitting LR and displaying coefficents\n",
        "reg = LinearRegression().fit(X_train, Y_train)\n",
        "reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWdvqow1mrYX"
      },
      "outputs": [],
      "source": [
        "# predict values\n",
        "y_pred = reg.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "459mk9Pf-IqP"
      },
      "source": [
        "**Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb3Y_rhznAxY"
      },
      "outputs": [],
      "source": [
        "# MSE and MAE calculations\n",
        "reg_pred = reg.predict(X_test)\n",
        "reg_mse = mean_squared_error(Y_test, reg_pred)\n",
        "reg_mae = mean_absolute_error(Y_test, reg_pred)\n",
        "\n",
        "print(\"Mean Squared Error (MSE): \", reg_mse)\n",
        "print(\"Mean Absolute Error (MAE): \", reg_mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9qtLqiN-Kt4"
      },
      "source": [
        "**Dataframe with Predicted Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQONZXviGdJH"
      },
      "outputs": [],
      "source": [
        "merged_data = np.concatenate((X_test, reg_pred.reshape(-1, 1)), axis=1)\n",
        "column_names = list(X_test.columns) + ['SalePrice']\n",
        "df_merged = pd.DataFrame(merged_data, columns=column_names)\n",
        "df_merged\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBF_eHGYnNJZ"
      },
      "source": [
        "# Streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSjBp7mTqco5"
      },
      "outputs": [],
      "source": [
        "# Required package installations\n",
        "!pip install -q streamlit\n",
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT61N0wC_sTC"
      },
      "outputs": [],
      "source": [
        "df_merged.to_csv('out.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvFnPkX1qToi"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "from pandas.api.types import (\n",
        "    is_categorical_dtype,\n",
        "    is_datetime64_any_dtype,\n",
        "    is_numeric_dtype,\n",
        "    is_object_dtype,\n",
        ")\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import altair as alt\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "st.title(\"ML-driven House Customization for Maximum Profit\")\n",
        "st.caption(\"MSCI 436 - Team 8\")\n",
        "\n",
        "#filtering\n",
        "st.header(\"Filtered Data\")\n",
        "def filter_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    st.caption(\"To filter through the columns, select the columns you would like.\")\n",
        "    modify = st.checkbox(\"Add filters\")\n",
        "\n",
        "    if not modify:\n",
        "        return df\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # Try to convert datetimes into a standard format (datetime, no timezone)\n",
        "    for col in df.columns:\n",
        "        if is_object_dtype(df[col]):\n",
        "            try:\n",
        "                df[col] = pd.to_datetime(df[col])\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        if is_datetime64_any_dtype(df[col]):\n",
        "            df[col] = df[col].dt.tz_localize(None)\n",
        "\n",
        "    modification_container = st.container()\n",
        "\n",
        "    with modification_container:\n",
        "        to_filter_columns = st.multiselect(\"Filter dataframe on\", df.columns)\n",
        "        for column in to_filter_columns:\n",
        "            left, right = st.columns((1, 20))\n",
        "            # Treat columns with < 10 unique values as categorical\n",
        "            if is_categorical_dtype(df[column]) or df[column].nunique() < 10:\n",
        "                user_cat_input = right.multiselect(\n",
        "                    f\"Values for {column}\",\n",
        "                    df[column].unique(),\n",
        "                    default=list(df[column].unique()),\n",
        "                )\n",
        "                df = df[df[column].isin(user_cat_input)]\n",
        "            elif is_numeric_dtype(df[column]):\n",
        "                _min = float(df[column].min())\n",
        "                _max = float(df[column].max())\n",
        "                step = (_max - _min) / 100\n",
        "                user_num_input = right.slider(\n",
        "                    f\"Values for {column}\",\n",
        "                    min_value=_min,\n",
        "                    max_value=_max,\n",
        "                    value=(_min, _max),\n",
        "                    step=step,\n",
        "                )\n",
        "                df = df[df[column].between(*user_num_input)]\n",
        "            elif is_datetime64_any_dtype(df[column]):\n",
        "                user_date_input = right.date_input(\n",
        "                    f\"Values for {column}\",\n",
        "                    value=(\n",
        "                        df[column].min(),\n",
        "                        df[column].max(),\n",
        "                    ),\n",
        "                )\n",
        "                if len(user_date_input) == 2:\n",
        "                    user_date_input = tuple(map(pd.to_datetime, user_date_input))\n",
        "                    start_date, end_date = user_date_input\n",
        "                    df = df.loc[df[column].between(start_date, end_date)]\n",
        "            else:\n",
        "                user_text_input = right.text_input(\n",
        "                    f\"Substring or regex in {column}\",\n",
        "                )\n",
        "                if user_text_input:\n",
        "                    df = df[df[column].astype(str).str.contains(user_text_input)]\n",
        "\n",
        "    return df\n",
        "\n",
        "df_ui = pd.read_csv('out.csv')\n",
        "st.dataframe(filter_dataframe(df_ui))\n",
        "\n",
        "#Graphs\n",
        "st.header(\"Visualization\")\n",
        "\n",
        "#all features\n",
        "st.subheader(\"All features\")\n",
        "st.caption(\"Showing the relationship between all the features and the house price.\")\n",
        "cols = df_ui.columns.tolist()[:-1]\n",
        "st.line_chart(df_ui, x = \"SalePrice\", y = cols, )\n",
        "\n",
        "#line graph\n",
        "def line_graph():\n",
        "  st.subheader(\"Line Graphs: Quality, Year, Area\")\n",
        "  st.caption(\"Showing the relationship between features of the house and the sale price.\")\n",
        "  tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([\"Overall Quality\", \"Year Built\",\n",
        "                      \"Year Remodel\", \"Total Basement SF\", \"Above Ground Sqft\",\n",
        "                      \"Garage Area\", \"Wood Deck SF\", \"Open Porch SF\"])\n",
        "  with tab1:\n",
        "   st.line_chart(df_ui, x = \"OverallQual\", y = \"SalePrice\")\n",
        "   st.text(\"The overall quality of the house is measured from 1-10. As shown, as the overall\\n quality increases, so does the price.\")\n",
        "  with tab2:\n",
        "    st.line_chart(df_ui, x = \"YearBuilt\", y = \"SalePrice\")\n",
        "    st.text(\"The graph shows the relationship between the year built and the house sale price.\\n Indicating that the newer house prices are higher comapred to the houses built from\\n 1900s-1950s.\")\n",
        "  with tab3:\n",
        "    st.line_chart(df_ui, x = \"YearRemodAdd\", y = \"SalePrice\")\n",
        "    st.text(\"The remodal year shows a position correlation towards the house sale price. As the\\n remodal year becomes recent, the house sale price increases as well.\")\n",
        "  with tab4:\n",
        "    st.line_chart(df_ui, x = \"TotalBsmtSF\", y = \"SalePrice\")\n",
        "    st.text(\"As shown in the graph, the average total basement surface area is between\\n 600-1700 sqft, with the average house price range being approximately $100k to $300k.\")\n",
        "  with tab5:\n",
        "    st.line_chart(df_ui, x = \"GrLivArea\", y = \"SalePrice\")\n",
        "    st.text(\"This graph shows a strong positive correlation between the above ground sqft and\\n the house sale price.\")\n",
        "  with tab6:\n",
        "    st.line_chart(df_ui, x = \"GarageArea\", y = \"SalePrice\")\n",
        "    st.text(\"This graph shows the average garage area is between 600-850 sqft, with the highest\\n price at $440,101 with 831 sqft.\")\n",
        "  with tab7:\n",
        "    st.line_chart(df_ui, x = \"WoodDeckSF\", y = \"SalePrice\")\n",
        "    st.text(\"The graph shows that the average wood deck surface area is approximately between\\n 50-450 sqft.\")\n",
        "  with tab8:\n",
        "    st.line_chart(df_ui, x = \"OpenPorchSF\", y = \"SalePrice\")\n",
        "    st.text(\"\")\n",
        "\n",
        "line_graph()\n",
        "\n",
        "#plots with values that can be controlled\n",
        "def plot():\n",
        "  st.subheader(\"Line Graphs: Total Rooms, Baths, Garage Cars, Fireplaces\")\n",
        "  tab1, tab2, tab3, tab4, tab5 = st.tabs([\"Total Rooms Abv Ground\", \"Full Bath\", \"Half Bath\",\n",
        "                                   \"Garage Cars\", \"Fireplaces\"])\n",
        "  with tab1:\n",
        "    st.subheader(\"Line Graph - Total Rooms Abv Ground vs Sale price\")\n",
        "    st.caption(\"Showcasing the relationship between the total number of rooms above the ground and the house sale price.\")\n",
        "    df = pd.read_csv('out.csv')\n",
        "    df['TotRmsAbvGrd'] = df['TotRmsAbvGrd'].astype(str)\n",
        "    clist = df[\"TotRmsAbvGrd\"].unique().tolist()\n",
        "    total_rooms = st.multiselect(\"Select total number of rooms\", clist)\n",
        "    st.text(\"You selected: {}\".format(\", \".join(total_rooms)))\n",
        "    dfs = {TotRmsAbvGrd: df[df[\"TotRmsAbvGrd\"] == TotRmsAbvGrd] for TotRmsAbvGrd in total_rooms}\n",
        "    fig = go.Figure()\n",
        "    for TotRmsAbvGrd, df in dfs.items():\n",
        "        fig = fig.add_trace(go.Scatter(x=df[\"TotRmsAbvGrd\"], y=df[\"SalePrice\"], name=TotRmsAbvGrd))\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "  with tab2:\n",
        "    st.subheader(\"Line Graph - Full Bath vs Sale price\")\n",
        "    st.caption(\"Showcasing the relationship between the number of full baths and the house sale price.\")\n",
        "    df = pd.read_csv('out.csv')\n",
        "    df['FullBath'] = df['FullBath'].astype(str)\n",
        "    clist = df[\"FullBath\"].unique().tolist()\n",
        "    full_baths = st.multiselect(\"Select number of full baths\", clist)\n",
        "    st.text(\"You selected: {}\".format(\", \".join(full_baths)))\n",
        "    dfs = {FullBath: df[df[\"FullBath\"] == FullBath] for FullBath in full_baths}\n",
        "    fig = go.Figure()\n",
        "    for FullBath, df in dfs.items():\n",
        "        fig = fig.add_trace(go.Scatter(x=df[\"FullBath\"], y=df[\"SalePrice\"], name=FullBath))\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "  with tab3:\n",
        "    st.subheader(\"Line Graph - Half Bath vs Sale price\")\n",
        "    st.caption(\"Showcasing the relationship between the number of half baths and the house sale price.\")\n",
        "    df = pd.read_csv('out.csv')\n",
        "    df['HalfBath'] = df['HalfBath'].astype(str)\n",
        "    clist = df[\"HalfBath\"].unique().tolist()\n",
        "    half_baths = st.multiselect(\"Select number of half baths\", clist)\n",
        "    st.text(\"You selected: {}\".format(\", \".join(half_baths)))\n",
        "    dfs = {HalfBath: df[df[\"HalfBath\"] == HalfBath] for HalfBath in half_baths}\n",
        "    fig = go.Figure()\n",
        "    for HalfBath, df in dfs.items():\n",
        "        fig = fig.add_trace(go.Scatter(x=df[\"HalfBath\"], y=df[\"SalePrice\"], name=HalfBath))\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "  with tab4:\n",
        "    st.subheader(\"Line Graph - Garage Cars vs Sale price\")\n",
        "    st.caption(\"Showcasing the relationship between the number of cars that can fit in the garage and the house sale price.\")\n",
        "    df = pd.read_csv('out.csv')\n",
        "    df['Fireplaces'] = df['Fireplaces'].astype(str)\n",
        "    clist = df[\"Fireplaces\"].unique().tolist()\n",
        "    garage_cars = st.multiselect(\"Select number of cars\", clist)\n",
        "    st.text(\"You selected: {}\".format(\", \".join(garage_cars)))\n",
        "    dfs = {GarageCars: df[df[\"GarageCars\"] == GarageCars] for GarageCars in garage_cars}\n",
        "    fig = go.Figure()\n",
        "    for GarageCars, df in dfs.items():\n",
        "        fig = fig.add_trace(go.Scatter(x=df[\"GarageCars\"], y=df[\"SalePrice\"], name=GarageCars))\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "  with tab5:\n",
        "    st.subheader(\"Line Graph - Fireplaces vs Sale price\")\n",
        "    st.caption(\"Showcasing the relationship between the number of fireplaces and the house sale price.\")\n",
        "    df = pd.read_csv('out.csv')\n",
        "    df['Fireplaces'] = df['Fireplaces'].astype(str)\n",
        "    clist = df[\"Fireplaces\"].unique().tolist()\n",
        "    fireplaces = st.multiselect(\"Select number of fireplaces\", clist)\n",
        "    st.text(\"You selected: {}\".format(\", \".join(fireplaces)))\n",
        "    dfs = {Fireplaces: df[df[\"Fireplaces\"] == Fireplaces] for Fireplaces in fireplaces}\n",
        "    fig = go.Figure()\n",
        "    for Fireplaces, df in dfs.items():\n",
        "        fig = fig.add_trace(go.Scatter(x=df[\"Fireplaces\"], y=df[\"SalePrice\"], name=Fireplaces))\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "\n",
        "plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEXcS_MergGJ"
      },
      "outputs": [],
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50pr0TVdrh94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfcffe01-e4c1-49b3-a0a9-6b65bcdd7093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.74.18.89\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.301s\n",
            "your url is: https://free-mails-ring.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!curl ipv4.icanhazip.com\n",
        "!npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fod4jvtYgapO"
      },
      "source": [
        "### References\n",
        "1. *Auto-generate a dataframe filtering UI in Streamlit with filter_dataframe!* (2022, August 18). Streamlit. https://discuss.streamlit.io/t/auto-generate-a-dataframe-filtering-ui-in-streamlit-with-filter-dataframe/29470\n",
        "2. Epogrebnyak. (n.d.). ssg-dataset/app/pages/1_🍴_Forks_and_issues.py at main · epogrebnyak/ssg-dataset. GitHub. https://github.com/epogrebnyak/ssg-dataset/blob/main/app/pages/1_%F0%9F%8D%B4_Forks_and_issues.py\n",
        "3. Gusthema. (2023). *House Prices Prediction using TFDF. Kaggle.* https://www.kaggle.com/code/gusthema/house-prices-prediction-using-tfdf/notebook\n",
        "4. Pmarcelino. (2022). *Comprehensive data exploration with Python. *Kaggle. https://www.kaggle.com/code/pmarcelino/comprehensive-data-exploration-with-python#4.-Missing-data\n",
        "5. Richards, T. (2022). *Auto-generate a dataframe filtering UI in Streamlit with filter_dataframe! Streamlit.* https://blog.streamlit.io/auto-generate-a-dataframe-filtering-ui-in-streamlit-with-filter_dataframe/\n",
        "6. st.line_chart - Streamlit Docs. (n.d.). https://docs.streamlit.io/library/api-reference/charts/st.line_chart\n",
        "7. Streamlit multiselect line chart. (n.d.). Stack Overflow. https://stackoverflow.com/questions/71185462/streamlit-multiselect-line-chart\n",
        "8. Valkov, V. (2021, December 9). *Predicting House Prices with Linear Regression | Machine Learning from Scratch (Part II). Medium.* https://towardsdatascience.com/predicting-house-prices-with-linear-regression-machine-learning-from-scratch-part-ii-47a0238aeac1\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "hDpgfrCBFYDx",
        "d2foBeQNFawN",
        "gSdu98MkrLdC",
        "L1biISiO-B9s",
        "hQm-InNTyLzc",
        "RzRNxY7Mau_H",
        "YFxYtVg42mcV"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}